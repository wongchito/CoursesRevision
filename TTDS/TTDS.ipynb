{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Technologies for Data Science (INFR11145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions of Information Retrieval\n",
    "\n",
    "*Given query $Q$, find relevant documents $D$.*\n",
    "\n",
    "**Main issues:**\n",
    "- Effectiveness\n",
    "    - need to find relevant documents\n",
    "    - different from relational DBs\n",
    "    \n",
    "|&nbsp;|IR|DB|\n",
    "|---|---|---|\n",
    "|**Retrieving**|*Unstructured* data, free text with metadata|*Stuctured* data, clear semantics based on formal model|\n",
    "|**Queries**|Natural language, boolean|Formally-defined (SQL), unambiguous.|\n",
    "|**Result**|Imprecise (need to measure relevance)|Exact|\n",
    "|**Interaction with system**|Important|One-shot queries|\n",
    "\n",
    "- Efficiency\n",
    "    - need to find them quickly\n",
    "    - data constantly changes, need to keep up\n",
    "\n",
    "**Components:**\n",
    "- Documents\n",
    "    - *element* to be retrieved\n",
    "    - unstructured nature\n",
    "    - unique ID\n",
    "    - $N$ documents $\\rightarrow$ Collection\n",
    "- Queries\n",
    "    - text to express *information need*\n",
    "    - same information needs - multiple queries: North Carolina storm vs Florence\n",
    "    - same query - multiple information needs: Apple\n",
    "    - different forms: keywords, sample image, tune\n",
    "- Relevant documents\n",
    "    - similar vocabulary $\\rightarrow$ similar meaning \n",
    "    - similarity: string match, word overlap, retrieval model $P(D|Q)$\n",
    "    - challenges: not clear semantics (Shakespeare), inherent ambiguity (e.g. in queries), highly subjective\n",
    "\n",
    "**Bag-of-words:**\n",
    "- Re-ordering doesn't destroy topic\n",
    "- negations lost\n",
    "- not work for all languages (Chinese, images, music)\n",
    "\n",
    "**Systems perspective:**\n",
    "- Indexing process (offline)\n",
    "- Search (retrieval) process (online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laws of Text\n",
    "\n",
    "### Zipf's Law\n",
    "\n",
    "$$r \\times P_r \\cong \\text{const} \\quad \\Leftrightarrow \\quad P_r \\cong \\frac{\\text{const}}{r}$$\n",
    "\n",
    "- $r$: rank of term according to frequency\n",
    "- $P_r$: probability of appearance of term\n",
    "- Reciprocal proportion\n",
    "- $\\approx$ 50% terms appears once\n",
    "\n",
    "### Benford's Law\n",
    "\n",
    "$$P(d) = \\log (1 + \\frac{1}{d})$$\n",
    "\n",
    "- $d$: first digit of frequency\n",
    "- $P(d)$: pmf of $d$\n",
    "\n",
    "### Heap's Law\n",
    "\n",
    "$$v(n) = k \\times n^b$$\n",
    "\n",
    "- $n$: number of words\n",
    "- $v$: number of unique words in the $n$ words\n",
    "- $b$: typically $\\in (0.4,0.7)$\n",
    "- Accurate for most collections with different $k$ and $b$\n",
    "- Not ccurate when $n$ is small\n",
    "- Not saturated because of spelling errors, names, emails, codes, etc. \n",
    "\n",
    "### Contagion\n",
    "\n",
    "- Most words do not appear that much\n",
    "- Once you see a word $\\rightarrow$ expect to ee again\n",
    "- Like rare contagious disease\n",
    "- Terms appearing twice close to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "*Identify the optimal form of the term to be indexed to achieve the best retrieval performance.*\n",
    "\n",
    "### Tokenisation\n",
    "- Split at non-letter characters\n",
    "- For French, abstract\n",
    "- For German, compound splitter\n",
    "- For Chinese or Japanese, segmentation\n",
    "- Special setup in some applications (e.g. hashtags in social media)\n",
    "\n",
    "\n",
    "### Stopping\n",
    "- Stop words: the most common words (e.g. the, a, is)\n",
    "- $\\approx$ 30%~40% of text\n",
    "- Less influence on topic\n",
    "- New stop words in specific domains (e.g. 'RT' in tweets)\n",
    "- Trend to keep stop words in web search\n",
    "    - good compression techniques\n",
    "    - good query optimisation techniques\n",
    "    - probabilistic retrieval models give low wait\n",
    "\n",
    "### Normalisation\n",
    "- Case folding\n",
    "- Accents removal (e.g. caf√©)\n",
    "- Equivalence classes (e.g. Ph.D. vs PhD)\n",
    "- Be consistent between documents and queries\n",
    "\n",
    "### Stemming\n",
    "- Reduce morphological variations of words\n",
    "    - inflectional (plurals, tenses)\n",
    "    - derivational (verbs nouns)\n",
    "- Basic types\n",
    "    - Dictionary-based: use lists of related words\n",
    "    - Algorithmic\n",
    "        - remove suffixes in English\n",
    "        - but false negatives or false positives exist\n",
    "- Usually achieve 5%~10% retrieval effectiveness improvement in English\n",
    "- Even higher in e.g. Fininsh or Arabic\n",
    "\n",
    "### Limitations\n",
    "- Irregular verbs (e.g. saw vs see)\n",
    "- Different spellings (e.g. colour vs color)\n",
    "- Synonyms (e.g. car vs vehicle)\n",
    "- Solution: query expansion\n",
    "    - more vocabulary, longer query\n",
    "    - potentially more powerful, but less efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "**Document vectors:**\n",
    "- Each vector is a document\n",
    "- Each value is frequency/binary of each term\n",
    "- Collection matrix: all vectors\n",
    "![](document_vectors.png)\n",
    "(Adpated from [Lecture 5: Indexing (1) - Text Technologies for Data Science)](https://www.inf.ed.ac.uk/teaching/courses/tts/handouts2018/05Indexing.pdf)\n",
    "\n",
    "**Term vectors:**\n",
    "- Each vector is a term\n",
    "- Each value is frequency/binary in each document\n",
    "- Transpose of collection matrix\n",
    "![](inverted_vectors.png)\n",
    "(Adpated from [Lecture 5: Indexing (1) - Text Technologies for Data Science)](https://www.inf.ed.ac.uk/teaching/courses/tts/handouts2018/05Indexing.pdf)\n",
    "\n",
    "**Collection matrix:**\n",
    "- Terms against documents\n",
    "- Extremely sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted index\n",
    "- Sparse representation of collection matrix\n",
    "- Construction\n",
    "    1. Term sequence\n",
    "    1. Sorting by term then by docID\n",
    "    1. Posting\n",
    "- Inverted index\n",
    "```python\n",
    "{term: list(docID)}\n",
    "```\n",
    "- Inverted index with frequency\n",
    "```python\n",
    "{term: list({docID: count})}\n",
    "```\n",
    "- Proximity index\n",
    "```python\n",
    "{term: list(tuple(docID, term pos))}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching \n",
    "\n",
    "#### Boolean search\n",
    "- Boolean: exist / not-exist\n",
    "- Multiword search: logical operators (AND, OR, NOT)\n",
    "- Query processing: linear merge $O(n)$\n",
    "```python\n",
    "for i in set(index[term1] + index[term2]):\n",
    "    if i in index[term1] and i in index[term2]:\n",
    "        print i\n",
    "```\n",
    "\n",
    "#### Phrase search\n",
    "- Bi-gram index\n",
    "    - index size will explode\n",
    "- Use proximity search (with proximity 1)\n",
    "\n",
    "#### Proximity search\n",
    "- `#3(term1, term2)`\n",
    "- Query processing: linear merge + check terms positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extent index\n",
    "\n",
    "- Special term (e.g. link)\n",
    "```python\n",
    "{link: list(tuple(docID, start, end))}\n",
    "```\n",
    "- Special field (e.g. headline)\n",
    "```python\n",
    "{headline: list(tuple(docID, start, end))}\n",
    "{term: list(tuple(docID, pos+(end-start)))}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index compression\n",
    "\n",
    "- Delta encoding: store ID using delta (difference) from the previous ID\n",
    "- v-byte encoding\n",
    "    - variable byte storage\n",
    "    - high bit is <span style=\"color:red\">1</span>: read following 7 bits\n",
    "    - high bit is <span style=\"color:red\">0</span>: read following 7 bits and check next high bit\n",
    "    - examples\n",
    "        - 6: <span style=\"color:red\">1</span>0000110\n",
    "        - 129: <span style=\"color:red\">0</span>0000001<span style=\"color:red\">1</span>0000001\n",
    "- more compression = less storage = more processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary data structures\n",
    "\n",
    "#### Hashes\n",
    "- Hase each term to a integer\n",
    "- Pro: lookup is faster than tree - $O(1)$\n",
    "- Cons: \n",
    "    - no easy way to find minor variants\n",
    "    - no prefix search\n",
    "    - need to rehasing everything occasionally as vocabulary grows\n",
    "    \n",
    "#### B-tree\n",
    "- Pros:\n",
    "    - solve the prefix problem\n",
    "    - mitigate the rebalacing problem of binary search tree\n",
    "- Cons: slower - $O(\\log M)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permuterm indexes\n",
    "\n",
    "- Add \\$ at the end of the term and index all permutations\n",
    "- Add \\$ at the end of wild-card query and permutate until \\* occurs at the end\n",
    "- Look up term\n",
    "\n",
    "Example: `hello`\n",
    "- Indexing: `hello$`, `ello$h`, `llo$he`, `lo$hel`, `o$hell`, `$hello`\n",
    "- Query: `he*o` $\\rightarrow$ `he*o$` $\\rightarrow$ `o$he*`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character n-gram indexes\n",
    "\n",
    "Example: `monkey`, `moon` (bigrams)\n",
    "- Indexing: `$m`, `mo`, `on`, `nk`, `ke`, `ey`, `y$`, `$m`, `mo`, `oo`, `on`, `n$`\n",
    "- Query: `mon*`\n",
    "\n",
    "\n",
    "1. Transform query to `$m`, `mo`, `on`\n",
    "1. Find possible terms: `monkey`, `moon`\n",
    "1. Post-filter: eliminate `moon`\n",
    "1. Look up surviving terms `monkey` in document\n",
    "\n",
    "**Application: spelling correction**\n",
    "- E.g. OCR\n",
    "- Possible corrections = most matching results\n",
    "- E.g. elepgant $\\rightarrow$ elegant OR elephant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranked Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean retrieval\n",
    "\n",
    "- Pros: good for expert users with precise understanding of needs (e.g. patent search)\n",
    "- Cons: \n",
    "    - write Boolean queries\n",
    "    - need to go through thousands of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard coeffecient\n",
    "\n",
    "$$\\operatorname{jaccard}(A,B) = \\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "\n",
    "- Don't consider term frequency\n",
    "- Treat all terms equally\n",
    "- Driven by length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF\n",
    "\n",
    "\\begin{align}\n",
    "\\operatorname{df}(t) &= \\sum_{i=1}^N \\mathbb 1(t \\in d_i) \\\\\n",
    "\\operatorname{idf}(t) &= \\log_{10} \\frac{N}{\\operatorname{df}(t)} \\\\\n",
    "\\operatorname{tf}(t,d_i) &= \\#\\{t \\in d_i\\} \\\\\n",
    "w_{t,d_i} &= \\left( 1 + \\log_{10} \\operatorname{tf}(t,d_i) \\right) \\times \\operatorname{idf}(t) \\\\\n",
    "\\operatorname{score}(q,d_i) &= \\sum_{t \\in q \\cap d_i} w_{t,d_i}\n",
    "\\end{align}\n",
    "\n",
    "- $\\operatorname{idf}$ (inverse document frequency) measures the importance of a term $t$ in a collection $\\{d_i\\}$\n",
    "- $\\operatorname{tf}$ (term frequency) measures the importance of a term $t$ in a document $d$\n",
    "- $\\operatorname{cf}$ (collection frequency, $\\displaystyle \\sum_{i=1}^N \\# \\{t \\in d_i\\}$) is less commonly used in IR\n",
    "- SMART notation: `ddd.qqq`\n",
    "    - Example: `lnc.ltc`\n",
    "        - For documents: logarithm of tf, no df (1), cosine normalisation\n",
    "        - For queries: logarithm of tf, inverse df, cosine normalisation\n",
    "    - Table of acronyms\n",
    "    \n",
    "|Term Frequency|Document Frequency|Normalisation|\n",
    "|---|---|---|\n",
    "|`n`: natural|`n`: no (1)|`n`: none (1)|\n",
    "|`l`: logarithm|`t`: idf|`c`: cosine|\n",
    "|`a`: augmented|`p`: prob idf (like ReLU)|`u`: pivoted unqiue|\n",
    "|`b`: boolean|&nbsp;|`b`: byte size|\n",
    "|`L`: log ave|&nbsp;|&nbsp;|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector space model (VSM)\n",
    "\n",
    "\\begin{align}\n",
    "M &= \\#\\{q \\cap d_i\\} \\\\\n",
    "\\mathbf q &= (w_{t_1, q}, w_{t_2,q}, \\ldots, w_{t_M, q})^\\top \\\\\n",
    "\\mathbf d_i &= (w_{t_1, d_i}, w_{t_2, d_i}, \\ldots, w_{t_M, d_i})^\\top \\\\\n",
    "\\operatorname{score}(q, d_i) &= \\cos(\\mathbf q, \\mathbf d_i) = \\frac{\\mathbf q^\\top \\mathbf d_i}{\\|\\mathbf q\\|_2 \\|\\mathbf d_i\\|_2} = \\frac{\\sum_{t \\in q \\cap d_i} w_{t,d_i} w_{t,q}}{\\sqrt{\\sum_{j=1}^M w_{t_j,q}^2} \\sqrt{\\sum_{j=1}^M w_{t_j,d_i}^2}}\n",
    "\\end{align}\n",
    "\n",
    "- Heuristic\n",
    "- No notion of relevance\n",
    "- Any weighting scheme, similarity measure can be used\n",
    "- Components are not interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability ranking principle (PRP)\n",
    "\n",
    "- Rank docs by probability of relevance: $P(R|D_{r_1}) > P(R|D_{r_2}) > \\cdots$\n",
    "- Estimate probability as accurate as possible: $\\hat P(R|D) \\approx P(R|D)$\n",
    "- Estimate with all possibly available data: $\\hat P(R|D, Q, \\text{Session}, \\text{Context}, \\text{User profile}, \\ldots)$\n",
    "- Classification problem: $D$ is relevant if $P(R=0|D) > P(R=1|D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okapi BM25 model\n",
    "\n",
    "$$w_{t,d_i} = \\frac{\\operatorname{tf}(t,d_i)}{k \\frac{L_{d_i}}{\\bar L} + \\operatorname{tf}(t,d_i) + 0.5} \\times \\log_{10} \\frac{N - \\operatorname{df}(t) + 0.5}{\\operatorname{df}(t) + 0.5}$$\n",
    "\n",
    "- Best practices $k=1.5$\n",
    "- $\\displaystyle \\bar L = \\frac{1}{N} \\sum_{i=1}^N L_{d_i}$\n",
    "\n",
    "**Assumptions:**\n",
    "- Binary features (term occurrence)\n",
    "- Terms are independence (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language model (LM)\n",
    "\n",
    "- The likelihood $P(q|M_d)$ of generating query $q=\\{t_1, \\ldots, t_K\\}$ from language model $M_d$\n",
    "- Rank docs based on posterior $P(d|q) \\propto P(q|M_d) P(d)$\n",
    "- Prior $P(d)$ often chosen to be Uniform\n",
    "\n",
    "|Model|Likelihood|\n",
    "|---|---|\n",
    "|Unigram LM|$$P(q|M_d) = \\prod_{k=1}^K P(t_k|M_d) = \\prod_{\\text{unique }t} P(t|M_d)^{\\operatorname{tf}(t,q)}$$|\n",
    "|Stochastic LM|$$P(q|M_d) = P(t_1|M_d) \\prod_{k=2}^K P(t_k|M_d, t_{k-1}, \\ldots, t_1)$$|\n",
    "|Bigram LM|$$P(q|M_d) = P(t_1|M_d) \\prod_{k=2}^K P(t_k|M_d, t_{k-1})$$|\n",
    "\n",
    "- MLE $\\displaystyle \\hat P(t|M_d) = \\frac{\\operatorname{tf}(t,d)}{L_d}$ (0 if term not occured in $d$)\n",
    "\n",
    "**Mixture model (Jelinek-mercer smoothing):**\n",
    "\n",
    "$$P(t|d) = \\lambda P(t|M_d) + (1-\\lambda) P(t|M_c)$$\n",
    "\n",
    "- Large $\\lambda$: 'conjunctive-like' search - tends to retrieve docs containing all query words\n",
    "- Small $\\lambda$: more disjunctive, suitable for long queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "|&nbsp;|relevant|irrelevant|\n",
    "|---|---|---|\n",
    "|**retrieved**|TP|FP|\n",
    "|**not retrieved**|FN|TN|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ranking\n",
    "\n",
    "|Measure|Formula|Notes|\n",
    "|---|---|---|\n",
    "|Precision|$$P=\\frac{\\text{TP}}{\\text{TP}+\\text{FP}}$$|High precision may miss many (less) relevant docs|\n",
    "|Recall|$$R=\\frac{\\text{TP}}{\\text{TP}+\\text{FN}}$$|High recall may contain many irrelevant docs|\n",
    "|Accuracy|$$A=\\frac{\\text{TP}+\\text{TN}}{\\text{TP}+\\text{FP}+\\text{TN}+\\text{FN}}$$|TN dominates the result if #irrelevant >> #relevant|\n",
    "|Balanced F-measure|$$F_1=\\frac{2 \\cdot P \\cdot R}{P+R}$$|Harmonic mean of precision and recall. Emphasises the importance of small values|\n",
    "|General F-measure|$$F_\\beta=\\frac{(\\beta^2+1) \\cdot P \\cdot R}{\\beta^2P + R}$$|Controls the importance of recall (than precision)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ranking (binary relevance)\n",
    "\n",
    "- Precision @ K (P@K): Cut-off ranked list at rank K then calculate precision\n",
    "    - (average badly)\n",
    "- R-Precision: P@R where R is the number of known relevant docs\n",
    "    - R is different given different query\n",
    "    - (not realistic)\n",
    "- Average Precision (AP): $\\displaystyle \\operatorname{AP}(q)=\\frac{1}{\\#\\mathrm{Rel}_q} \\sum_{k=1}^{n} P(k) \\mathbb 1(d_k \\in \\mathrm{Rel}_q)$\n",
    "    - Expectation of P@K where K is uniformly distributed\n",
    "- Mean Average Precision (MAP): $\\displaystyle \\operatorname{MAP} = \\frac{1}{Q} \\sum_{q=1}^Q \\operatorname{AP}(q)$\n",
    "    - A mix between precision and recall\n",
    "    - Highly focus on finding relevant docs as early as possible\n",
    "    - Most commonly used for most IR tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded relevance\n",
    "\n",
    "|Measure|Formula|\n",
    "|---|---|\n",
    "|Gain|$G(k)=$ grade of retrieved doc at rank $k$|\n",
    "|Discounted Gain|$$\\operatorname{DG}(k) = \\begin{cases}\n",
    "\\operatorname{G}(k) & k=1 \\\\\n",
    "\\displaystyle \\frac{\\operatorname{G}(k)}{\\log_2 k} & k \\geq 2\n",
    "\\end{cases}$$|\n",
    "|Discounted Cumulative Gain|$$\\operatorname{DCG}(k) = \\sum_{i=1}^k \\operatorname{DG}(k)$$|\n",
    "|Ideal Gain|$$\\operatorname{iG}(k) = G_{(k)}$$ (should include all relevant docs)|\n",
    "|Ideal DG|$$\\operatorname{iDG}(k) = \\begin{cases}\n",
    "\\operatorname{iG}(k) & k=1 \\\\\n",
    "\\displaystyle \\frac{\\operatorname{iG}(k)}{\\log_2 k} & k \\geq 2\n",
    "\\end{cases}$$|\n",
    "|Ideal DCG|$$\\operatorname{iDCG}(k) = \\sum_{i=1}^k \\operatorname{iDG}(k)$$|\n",
    "|Normalised DCG|$$\\operatorname{nDCG}(k) = \\frac{\\operatorname{DCG}(k)}{\\operatorname{iDCG}(k)}$$|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Retrieval Conferences (TREC)\n",
    "\n",
    "- Main IR evaluation compaign\n",
    "- To search a set of docs of given genre and domain\n",
    "- Formed of a set of tracks, each track has a set of search tasks\n",
    "\n",
    "#### Collection\n",
    "\n",
    "- Cover most of the domains in life\n",
    "- A set of hundreds of thousands of docs\n",
    "- Format:\n",
    "```xml\n",
    "<DOC>\n",
    "    <DOCNO>1234</DOCNO>\n",
    "    <TEXT>Plain text of the document</TEXT>\n",
    "</DOC>\n",
    "```\n",
    "\n",
    "#### Topic\n",
    "\n",
    "- Query sets provided for each collection\n",
    "- Generated by experts\n",
    "- Format:\n",
    "```xml\n",
    "<num>189</num>\n",
    "<title>the query text</title>\n",
    "<desc>description of what is meant by the query</desc>\n",
    "<narr>what should be considered relevant</narr>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "\n",
    "1. Each system submit top 1000 docs per topic\n",
    "1. For each system, judge top 100 docs by\n",
    "    - single poll, remove duplicates, random rank\n",
    "    - judged by the person developing the topic\n",
    "1. Treat unevaluated docs as irrelevant\n",
    "1. Compute MAP down to 1000 docs\n",
    "\n",
    "\n",
    "- Large number of reasonable systems\n",
    "- Systems must not all do the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's kappa\n",
    "\n",
    "$$\\varkappa = \\frac{P(A)-P(E)}{1-P(E)}$$\n",
    "\n",
    "- $P(A) = P(J_1=1, J_2=1) + P(J_1=0, J_2=0)$ (probability of judges agree)\n",
    "- $P(E) = P(J_1=1)P(J_2=1) + P(J_1=0)P(J_2=0)$ (agreement by chance)\n",
    "\n",
    "$$\\varkappa \\in \\begin{cases}\n",
    "\\{1\\} & \\text{total agreement} \\\\\n",
    "(0.8, 1) & \\text{good agreement} \\\\\n",
    "(0.67, 0.8] & \\text{'fair' agreement} \\\\\n",
    "(0, 0.67) & \\text{data providing a suspicious basis for an evaluation} \\\\\n",
    "\\{0\\} & \\text{chance agreement} \\\\\n",
    "[-1,0) & \\text{worse than random}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A/B testing\n",
    "\n",
    "1. Have most users use old system\n",
    "1. Divert a small proportion of traffic to the new system\n",
    "1. Evaluate with automatic measures\n",
    "1. Use significance test\n",
    "\n",
    "**Paired t-test (one-sided):**\n",
    "\n",
    "$$t = \\frac{\\bar d \\cdot \\sqrt{n}}{\\operatorname{std}(d)} \\sim t_{n-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic thesaurus\n",
    "\n",
    "**Co-occurence:**\n",
    "\n",
    "$$\\mathbf C = \\mathbf{AA}^\\top$$\n",
    "\n",
    "- Pros: unsupervised\n",
    "- Cons: \n",
    "    - related words more than real synonyms\n",
    "    - computationally expensive\n",
    "    \n",
    "**Parallel corpus:**\n",
    "\n",
    "- Sets of two parallel corpus in two different languages (source and target lang)\n",
    "- Main training resource for machine translation systems\n",
    "- Improvement not consistent due to lack of context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevance feedback\n",
    "\n",
    "- Users give feedback to IR system (relevant/irrelevant)\n",
    "- Can improve recall and precision\n",
    "- More useful for increasing recall\n",
    "- One round is often very useful. Two rounds is sometimes marginally useful\n",
    "- Long queries require high cost and long response\n",
    "- Users are reluctant to provide feedback\n",
    "\n",
    "**Rocchio algorithm:**\n",
    "\n",
    "$$\\mathbf q_{\\text{modified}} = \\alpha \\mathbf q_0 + \\beta \\frac{1}{|D_{\\text{rel}}|} \\sum_{\\mathbf d_j \\in D_{\\text{rel}}} \\mathbf d_j - \\gamma \\frac{1}{|D_{\\text{irrel}}|} \\sum_{\\mathbf d_j \\in D_{\\text{irrel}}} \\mathbf d_j$$\n",
    "\n",
    "- $\\mathbf q_0$: original query vector\n",
    "- $\\alpha$: original query weight\n",
    "- $\\beta$: positive feedback weight\n",
    "- $\\gamma$: negative feedback weight\n",
    "- Usually $\\beta> \\gamma$\n",
    "\n",
    "**Pseudo (blind) relevance feedback:**\n",
    "1. Retrieve ranked list of hits of user's query\n",
    "1. Assume top $k$ docs are relevant\n",
    "1. Do relevance feedback (e.g. Rocchio)\n",
    "1. Typically set $\\gamma=0$\n",
    "\n",
    "\n",
    "- Still can go wrong\n",
    "- Several iterations can lead to query drift\n",
    "- Proven to be useful in news (names, entities), social (hashtags) and web (clicks) search\n",
    "- Challenging in patent search\n",
    "- Most basic QE (unsupervised, lang independent)\n",
    "- Evaluation: compared to baseline (no PRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IR Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printed documents retrieval\n",
    "\n",
    "Challenge: image of text $\\rightarrow$ OCR $\\rightarrow$ text with errors\n",
    "\n",
    "Text preprocessing methods:\n",
    "- [n-gram character representation](#Character-n-gram-indexes) of OCR\n",
    "- OCR correction with error model\n",
    "    - select part of OCR text and correct manually\n",
    "    - train error model\n",
    "- Query garbling with error model\n",
    "    - generate possible errors of query\n",
    "- OCR correction with edit distance\n",
    "    - edit distance between generated candidates\n",
    "- Multi-OCR text fusion\n",
    "    - word alignment between OCRs\n",
    "- Fail when errors > 50%\n",
    "\n",
    "Solution:\n",
    "- OCRless search\n",
    "    - Indexing\n",
    "        1. Segment image of text to elements\n",
    "        1. Clustering and assign ID\n",
    "        1. Convert doc to IDs\n",
    "    - Querying\n",
    "        1. Draw query\n",
    "        1. Replace with candidate IDs\n",
    "        1. Search index of IDs\n",
    "    - Effective and fast\n",
    "    - Robust to OCR errors\n",
    "    - No training resources required\n",
    "    - Lang independent\n",
    "    - State-of-art: CAPTCHA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patent search\n",
    "\n",
    "- Recall-oriented (not to miss a relevant doc)\n",
    "- Huge number of docs to check\n",
    "- AP foucuses on finding relevant docs earlier but less focus on recall\n",
    "\n",
    "**Patent retrieval evaluation score (PRES):**\n",
    "\n",
    "$$\\mathrm{PRES} = 1 - \\frac{\\frac{1}{n} \\sum r_i - \\frac{n+1}{2}}{N_{\\text{max}}}$$\n",
    "\n",
    "- $r_i$: rank of $i$-th relevant doc\n",
    "- $n$: number of relevant docs\n",
    "- $N_{\\text{max}}$: max number of checked docs\n",
    "- Give higher score for systems achieving higher recall and better average relative ranking\n",
    "- Dependent on user's effor ($N_{\\text{max}}$)\n",
    "- Robust to incomplete relevance judgements\n",
    "\n",
    "**MT4IR:**\n",
    "- Neglect morphological and syntactic features of output\n",
    "- Faster in translation and more effective in retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social search\n",
    "\n",
    "- Report/comment/discuss news\n",
    "- Reflect public interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "\n",
    "- Types: binary, single-label multi-class (SLMC), multi-label multi-class (MLMC)\n",
    "- Dimensions: by topic, sentiment, language, genre, author, usefulness\n",
    "- Supervised learning classification\n",
    "    1. Feature extraction\n",
    "        - BOW, word n-grams, char n-grams\n",
    "        - sentence structure, topic-based features, non-textual features (e.g. avg doc lenght, % of words start with upper-cased letter, % of links/hashtags in text)\n",
    "        - preprocessing (case-folding, punctuations, stopping, stemming)\n",
    "        - start with cap, all cap, repeated chars\n",
    "    1. Feature selection\n",
    "        - high dimensional, sparse, high computational cost, overfitting\n",
    "        - find top $k$ representative features for each class and union\n",
    "        - selection funtions:\n",
    "            - document frequency: basic, will select stop words as feature\n",
    "            - mutual information: how term appear in this class compared to others, highly used\n",
    "            - Pearson's chi-squared: used more in comparisons between classes\n",
    "        - feature synthesis: matrix decomposition (PCA), distributional semantics, word embeddings\n",
    "    1. Feature weighting\n",
    "        - binary, numeric (TFIDF, BM25, tf*)\n",
    "        - cosine similarity, dot product\n",
    "    1. Classifier training\n",
    "        - any supervised learning algorithm (SVM, KNN)\n",
    "        - 'No-free-lunch principle' (no learning alg outperforms all others in all contexts)\n",
    "        - split data (training/validation/testing), cross-validation\n",
    "    1. Evaluation\n",
    "        - baseline: random classification, majority class, BOW\n",
    "        - accuracy, precision, recall, F1, macro-F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Search\n",
    "\n",
    "- Web document collections are: massive, graph, unstructured, growth, content are dynamically generated\n",
    "- Larger index > better retrieval algorithm\n",
    "\n",
    "**PageRank:**\n",
    "\n",
    "\\begin{align}\n",
    "\\operatorname{PR}_0(x_i) &= \\frac{100\\%}{N} \\quad i=1,\\ldots,N \\\\\n",
    "\\operatorname{PR}_{t+1}(x_i) &= \\frac{1-\\lambda}{N} + \\lambda \\sum_{y \\to x_i} \\frac{\\operatorname{PR}_t(y)}{L_{\\text{out}}(y)}\n",
    "\\end{align}\n",
    "\n",
    "- One inlink from high PR > many inlink from low PR\n",
    "\n",
    "**Anchor text:**\n",
    "- Short, concise description of target page content\n",
    "- Imporove retrieval\n",
    "\n",
    "**Link spam:**\n",
    "- Trackbak links\n",
    "- Links from comments on sites with high PR\n",
    "- Link farms\n",
    "    - fake densely-connected graph\n",
    "    - hundreds of web domains but hosted on one machine\n",
    "\n",
    "**Histroy:**\n",
    "- Sponsored search\n",
    "\n",
    "**User's need:**\n",
    "- Informational - 40%\n",
    "- Navigational - 25%\n",
    "- Transactional - 35%\n",
    "- Gray areas - 10%\n",
    "\n",
    "**Search engine optimisation (SEO):**\n",
    "- To turn your web page to rank highly, rather than paying for placement\n",
    "- Simple form: rely on TFIDF, repeating terms multipule times, misleading meta-tags\n",
    "- Cloaking: serve fake content to search engine spider\n",
    "- Duplicate detection:\n",
    "    - Near-duplication: use similarity threshold\n",
    "    - MiniHash\n",
    "        1. Segment docs\n",
    "        1. Shingles (word n-gram)\n",
    "        1. Calculate [Jaccard coeffecient](#Jaccard-coeffecient)\n",
    "        \n",
    "**Web crawling:**\n",
    "1. Begin with known seed URLs from frontier\n",
    "1. Fetch\n",
    "1. Parse, extract links, pass URL filter\n",
    "1. Check if doc has content alredy seen, remove duplicate\n",
    "1. Fetch from the queue and repeat 2\n",
    "\n",
    "\n",
    "- Must: \n",
    "    - polite: repect `robots.txt` stating what pages are allowed to crawl, avoid hitting too often (by inserting time gap)\n",
    "    - robust: immune to spider traps and malicious behavious\n",
    "- Should:\n",
    "    - capable of distributed operation\n",
    "    - scalable\n",
    "    - efficiency\n",
    "    - fetch high quality pages first\n",
    "    - continuous\n",
    "    - extensible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-wise\n",
    "\n",
    "- Function based on features of a single document\n",
    "- Similar to classification\n",
    "- Classic retrieval models are also point-wise\n",
    "- Refer to as information filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List-based\n",
    "\n",
    "- Loss function on a list of docs\n",
    "- Huge number of potential lists is challenge\n",
    "- Can develop tricks (re-ranking top $N$ retrieved by some fixed methods)\n",
    "- Still expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair-wise\n",
    "\n",
    "**RankingSVM:**\n",
    "\n",
    "- Better correlate to evaluation metrics than point-wise approaches (example in table)\n",
    "\n",
    "|Document|Ground-truth|Model 1|Model 2|\n",
    "|---|---|---|---|\n",
    "|**D1**|2|2|1|\n",
    "|**D2**|1|3|0|\n",
    "\n",
    "- Not directly optimise an evaluation metric\n",
    "\n",
    "**LambdaMART:**\n",
    "- Reorder pairs depending on contribution to the changes in target evaluation measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:** s1680642\n",
    "\n",
    "**Licensing:** <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
